{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/indra-roy/Cadiac-Arrest-Identification-and-Monitorying-System-by-Machine-Learning-Approach./blob/main/car_damage_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BDYZTWV7Md0W"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "import os\n",
        "import cv2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator #\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Read data path and check files**\n"
      ],
      "metadata": {
        "id": "jT6_Rh0FM-15"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "6HQXd8dSMtWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_path = \"/content/drive/MyDrive/car_dent_coco.zip (Unzipped Files)/car_dent_coco/train/\"\n",
        "test_data_path = \"/content/drive/MyDrive/car_dent_coco.zip (Unzipped Files)/car_dent_coco/test/\"\n",
        "valid_data_path = \"/content/drive/MyDrive/car_dent_coco.zip (Unzipped Files)/car_dent_coco/valid/\""
      ],
      "metadata": {
        "id": "Xngo383xNFPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "#print(glob.glob(str(train_data_path)+'/*.jpg'))\n",
        "#back_light-1---83-_jpg.rf.829f6df0f7e1032fac163a84da29a75e.jpg\n",
        "#sign_light--19-_jpg.rf.9170ffdd1abc3028910d4592a6aa9984.jpg"
      ],
      "metadata": {
        "id": "94-lU8uzNcMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# looking into the the data\n",
        "img = plt.imread(os.path.join(train_data_path, \"0118_JPEG.rf.29e679636575003fa9eb7a39b4040d8e.jpg\"))\n",
        "plt.imshow(img)\n",
        "height, width, dim = img.shape\n",
        "print(\"size of image (h x w)\",height,width)"
      ],
      "metadata": {
        "id": "FcSz3WEJNfUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Get a Image result **"
      ],
      "metadata": {
        "id": "WFGWKZHHNqt6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# looking into the the data\n",
        "img = plt.imread(os.path.join(train_data_path, \"1--1-_jpeg.rf.62f331d25cc13d269afeda0e08f51ad5.jpg\"))\n",
        "plt.imshow(img)\n",
        "height, width, dim = img.shape\n",
        "print(\"size of image (h x w)\",height,width)"
      ],
      "metadata": {
        "id": "Lgl7m40xNhen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Input**"
      ],
      "metadata": {
        "id": "112nhCFMN4Sc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_path"
      ],
      "metadata": {
        "id": "-fLuui1gNpaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Output**"
      ],
      "metadata": {
        "id": "c-vl4RmiN7wG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "'/content/drive/MyDrive/car_dent_coco.zip (Unzipped Files)/car_dent_coco/train/'"
      ],
      "metadata": {
        "id": "XATcJlMNN7JJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load Images Data**"
      ],
      "metadata": {
        "id": "fY_4jgrQOCaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = ImageDataGenerator(rescale=1/255)\n",
        "test = ImageDataGenerator(rescale=1/255)\n",
        "valid = ImageDataGenerator(rescale=1/255)\n",
        "\n",
        "img_width, img_height = 640, 640\n",
        "\n",
        "nb_train_samples = 2000\n",
        "nb_validation_samples = 800\n",
        "nb_epoch = 50\n",
        "\n",
        "train_dataset = train.flow_from_directory(directory = '/content/drive/MyDrive/car_dent_coco.zip (Unzipped Files)/car_dent_coco',classes = ['train']\n",
        "                                         ,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=32,\n",
        "        class_mode='binary')\n",
        "                                         \n",
        "test_dataset = test.flow_from_directory(directory = '/content/drive/MyDrive/car_dent_coco.zip (Unzipped Files)/car_dent_coco',classes = ['test']\n",
        "                                       ,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=16,\n",
        "        class_mode='binary')\n",
        "\n",
        "valid_dataset = test.flow_from_directory(directory = '/content/drive/MyDrive/car_dent_coco.zip (Unzipped Files)/car_dent_coco',classes = ['valid']\n",
        "                                        ,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=16,\n",
        "        class_mode='binary',\n",
        "        shuffle=True)\n"
      ],
      "metadata": {
        "id": "9G58CT2tOdBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Found 754 images belonging to 1 classes.\n",
        "\n",
        "Found 80 images belonging to 1 classes.\n",
        "\n",
        "Found 390 images belonging to 1 classes."
      ],
      "metadata": {
        "id": "QvnrhK-wPpMX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train model**"
      ],
      "metadata": {
        "id": "iUBwAC8oPyvW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense"
      ],
      "metadata": {
        "id": "DHdkMcYqPBZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dimensions of our images.\n",
        "img_width, img_height = 640, 640\n",
        "\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Convolution2D(32, (3, 3),padding='same',input_shape=(img_width, img_height,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Convolution2D(32,(3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Convolution2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "HFc0zdtYP3-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model: \"sequential\"\n",
        "_________________________________________________________________\n",
        " Layer (type)                Output Shape              Param #   \n",
        "=================================================================\n",
        " conv2d (Conv2D)             (None, 640, 640, 32)      896       \n",
        "                                                                 \n",
        " activation (Activation)     (None, 640, 640, 32)      0         \n",
        "                                                                 \n",
        " max_pooling2d (MaxPooling2D  (None, 320, 320, 32)     0         \n",
        " )                                                               \n",
        "                                                                 \n",
        " conv2d_1 (Conv2D)           (None, 318, 318, 32)      9248      \n",
        "                                                                 \n",
        " activation_1 (Activation)   (None, 318, 318, 32)      0         \n",
        "                                                                 \n",
        " max_pooling2d_1 (MaxPooling  (None, 159, 159, 32)     0         \n",
        " 2D)                                                             \n",
        "                                                                 \n",
        " conv2d_2 (Conv2D)           (None, 157, 157, 32)      9248      \n",
        "                                                                 \n",
        " activation_2 (Activation)   (None, 157, 157, 32)      0         \n",
        "                                                                 \n",
        " max_pooling2d_2 (MaxPooling  (None, 78, 78, 32)       0         \n",
        " 2D)                                                             \n",
        "                                                                 \n",
        " flatten (Flatten)           (None, 194688)            0         \n",
        "                                                                 \n",
        " dense (Dense)               (None, 64)                12460096  \n",
        "                                                                 \n",
        " activation_3 (Activation)   (None, 64)                0         \n",
        "                                                                 \n",
        " dropout (Dropout)           (None, 64)                0         \n",
        "                                                                 \n",
        " dense_1 (Dense)             (None, 1)                 65        \n",
        "                                                                 \n",
        " activation_4 (Activation)   (None, 1)                 0         \n",
        "                                                                 \n",
        "=================================================================\n",
        "\n",
        "Total params: 12,479,553\n",
        "\n",
        "Trainable params: 12,479,553\n",
        "\n",
        "Non-trainable params: 0"
      ],
      "metadata": {
        "id": "VgK6BPsVP7kX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Dense,Activation,Dropout, Conv2D, MaxPool2D\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "earlystop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=1, min_delta=0.001)\n",
        "modelcheck = ModelCheckpoint('best_model.hdf5', monitor='val_accuracy',verbose=1,save_best_only=True,mode='max')\n",
        "history = model.fit(train_dataset, \n",
        "                    validation_data=test_dataset,\n",
        "                    epochs=64,\n",
        "                    callbacks=[earlystop,modelcheck],\n",
        "                    batch_size=32)"
      ],
      "metadata": {
        "id": "Y_dFuM9oQFVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Epoch 1/64\n",
        "\n",
        "24/24 [==============================] - ETA: 0s - loss: 0.0294 - accuracy: 0.9801\n",
        "\n",
        "Epoch 00001: val_accuracy improved from -inf to 1.00000, saving model to best_model.hdf5\n",
        "\n",
        "24/24 [==============================] - 52s 2s/step - loss: 0.0294 - accuracy: 0.9801 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
        "\n",
        "Epoch 2/64\n",
        "\n",
        "24/24 [==============================]- ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
        "\n",
        "Epoch 00002: val_accuracy did not improve from 1.00000\n",
        "\n",
        "24/24 [==============================] - 17s 669ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
        "\n",
        "Epoch 0002: early stopping"
      ],
      "metadata": {
        "id": "PzjV8V1RQI4q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('car_model.hdf5')"
      ],
      "metadata": {
        "id": "v2JTzG7PQkRo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the model for Future Inferences\n",
        "\n",
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"model.h5\")"
      ],
      "metadata": {
        "id": "YUGFXOwGQ9bS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils.vis_utils import plot_model\n",
        "plot_model(model,show_shapes=True,show_layer_names=True, to_file='model.png')"
      ],
      "metadata": {
        "id": "sJYqPySpQ_m_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluate the model**"
      ],
      "metadata": {
        "id": "meeVFo0NREId"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Test accuracy achieved', history.history['val_accuracy'][-2])"
      ],
      "metadata": {
        "id": "T7hIl7oORBa0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Test accuracy achieved 1.0"
      ],
      "metadata": {
        "id": "2SHpIjPYpTK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate_generator(generator=valid_dataset,steps=32)\n",
        "# model.evaluate(generator=valid_dataset,steps=64)"
      ],
      "metadata": {
        "id": "xipI_3sVpdJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
        "  \"\"\"Entry point for launching an IPython kernel.\n",
        "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 32 batches). You may need to use the repeat() function when building your dataset."
      ],
      "metadata": {
        "id": "SOHiWOFkphHz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "[0.0, 1.0]\n"
      ],
      "metadata": {
        "id": "Ej4U2tShpibv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Predict the output**"
      ],
      "metadata": {
        "id": "x8KbR-jupoCa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset.reset()\n",
        "pred=model.predict_generator(test_dataset,\n",
        "steps=128,\n",
        "verbose=1)\n",
        "predicted_class_indices=np.argmax(pred,axis=1)"
      ],
      "metadata": {
        "id": "Gdgsr1MQpeEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
        "  after removing the cwd from sys.path.\n",
        "  5/128 [>.............................] - ETA: 30sWARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 128 batches). You may need to use the repeat() function when building your dataset.\n",
        "128/128 [==============================] - 1s 9ms/step"
      ],
      "metadata": {
        "id": "mnWIPM_JqcKN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_class_indices\n",
        "\n",
        "# 0 = car damage"
      ],
      "metadata": {
        "id": "IzbKwEaMqehd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "rray([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ],
      "metadata": {
        "id": "1a26nwxQqjq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = (train_dataset.class_indices)\n",
        "labels = dict((v,k) for k,v in labels.items())\n",
        "predictions = [labels[k] for k in predicted_class_indices]\n",
        "#save predictions to results file\n",
        "filenames=test_dataset.filenames\n",
        "results=pd.DataFrame({\"Filename\":filenames,\n",
        "                      \"Predictions\":predictions})\n",
        "results.to_csv(\"results.csv\",index=False)"
      ],
      "metadata": {
        "id": "YKSXQsm6qlsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Validate Model Output**"
      ],
      "metadata": {
        "id": "ugn2_-ofqn_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Check data in validation dataset\n",
        "import glob\n",
        "# print(glob.glob(str(valid_data_path)+'/*.jpg'))"
      ],
      "metadata": {
        "id": "fWCagQ7fqrUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Our predict function\n",
        "def predictImage(filename):\n",
        "    \n",
        "    img = image.load_img(filename)\n",
        "    plt.imshow(img)\n",
        "    \n",
        "    Y = image.img_to_array(img)\n",
        "    X = np.expand_dims(Y,axis=0)\n",
        "    val = model.predict(X)\n",
        "    print(val)\n",
        "    if val < 0.5:\n",
        "        plt.xlabel(\"Car Damage\",fontsize=30)\n",
        "    elif val >= 0.5:\n",
        "        plt.xlabel(\"Car Not Damage\",fontsize=30)\n",
        "        \n",
        "        \n",
        "u = '/content/drive/MyDrive/car_dent_coco.zip (Unzipped Files)/car_dent_coco/valid/11_jpeg.rf.2a13b0d994e1fa1d95bf7f0292680f36.jpg'\n",
        "predictImage(u)"
      ],
      "metadata": {
        "id": "l79uftV1qtlK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Car Damage Image**"
      ],
      "metadata": {
        "id": "7A7Xj0cxqzUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "u = '/content/drive/MyDrive/car_dent_coco.zip (Unzipped Files)/car_dent_coco/valid/17_jpeg.rf.482e834e083b0c3b9bada20c046c231d.jpg'\n",
        "predictImage(u)"
      ],
      "metadata": {
        "id": "czg1IXegq3VJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "u = '/content/drive/MyDrive/car_dent_coco.zip (Unzipped Files)/car_dent_coco/valid/6--1-_jpeg.rf.81ff429e14d467f82f38468f96e21eaf.jpg'\n",
        "predictImage(u)"
      ],
      "metadata": {
        "id": "fkZ0Wly7q8HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Car Damage Image**\n"
      ],
      "metadata": {
        "id": "yeGQaqf2rBLC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "u = '/content/drive/MyDrive/car_dent_coco.zip (Unzipped Files)/car_dent_coco/valid/25_jpeg.rf.7d6a010838584cb14aaa1d883d1e8a86.jpg'\n",
        "predictImage(u)"
      ],
      "metadata": {
        "id": "w20HBf0sx1Ai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Car Damage Image**"
      ],
      "metadata": {
        "id": "jMKeIusdx7hK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**StreamLit Web app**"
      ],
      "metadata": {
        "id": "f4tjx4-xyEBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install --upgrade streamlit\n",
        "# !pip install streamlit\n",
        "# !pip install pyngrok\n",
        "# !pip install ipykernel>=5.1.2\n",
        "# !pip install pydeck\n",
        "# !pip install --upgrade ipykernel"
      ],
      "metadata": {
        "id": "DvLo61T7x45v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "PAGE_CONFIG = {\"page_title\":\"StColab.io\",\"page_icon\":\":smiley:\",\"layout\":\"centered\"}\n",
        "st.beta_set_page_config(**PAGE_CONFIG)\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from PIL import Image, ImageOps\n",
        "def import_and_predict(image_data, model):\n",
        "    \n",
        "        size = (150,150) \n",
        "        image = ImageOps.fit(image_data)\n",
        "        image = np.asarray(image)\n",
        "        image = (image.astype(np.float32) / 255.0)\n",
        "\n",
        "        img_reshape = image[np.newaxis,...]\n",
        "\n",
        "        prediction = model.predict(img_reshape)\n",
        "        \n",
        "        return prediction\n",
        "    \n",
        "model = tf.keras.models.load_model('car_model.hdf5')\n",
        "\n",
        "st.write(\"\"\"\n",
        "         # Car Damage Detection\n",
        "         \"\"\"\n",
        "         )\n",
        "st.write(\"This is a simple image classification web app to predict damage\")\n",
        "file = st.file_uploader(\"Please upload an image file\", type=[\"jpg\", \"png\"])    \n",
        "if file is None:\n",
        "    st.text(\"Please upload an image file\")\n",
        "else:\n",
        "    image = Image.open(file)\n",
        "    st.image(image, use_column_width=True)\n",
        "    prediction = import_and_predict(image, model)\n",
        "    \n",
        "    if np.argmax(prediction) < 0.5:\n",
        "        st.write(\"Car Damage!\")\n",
        "    elif np.argmax(prediction) >= 0.5:\n",
        "        st.write(\"Car Not Damage!\")\n",
        "    \n",
        "    \n",
        "    st.text(\"Probability (0: Car_Damage, 1: Car_Not_Damage\")\n",
        "    st.write(prediction)"
      ],
      "metadata": {
        "id": "fm5wB3Pa4AFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Writing app.py**"
      ],
      "metadata": {
        "id": "pRM75GRJ4FT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# run the app on local system\n",
        "!streamlit run app.py &>/dev/null&"
      ],
      "metadata": {
        "id": "3r9b6RsV4Kb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A url is created to host the app\n",
        "from pyngrok import ngrok\n",
        "# Setup a tunnel to the streamlit port 8501\n",
        "public_url = ngrok.connect(port='8501')\n",
        "public_url"
      ],
      "metadata": {
        "id": "8Om7r74n4NRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<NgrokTunnel: \"http://2c42-35-194-35-114.ngrok.io\" -> \"http://localhost:80\">**"
      ],
      "metadata": {
        "id": "4Eqfex8q4Q3K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# shutdown the app\n",
        "!pgrep streamlit\n",
        "ngrok.kill()"
      ],
      "metadata": {
        "id": "k6ALeO8O4Oyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2329"
      ],
      "metadata": {
        "id": "UZvtdvHE4VRu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# run streamlit on local system\n",
        "# !streamlit run /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py [ARGUMENTS]\n",
        "# !streamlit run /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py [ARGUMENTS] --server.enableWebsocketCompression=false --server.enableXsrfProtection=false  --server.port=8888\n"
      ],
      "metadata": {
        "id": "vsZ-zb8l4YzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Deploy model with Flask**"
      ],
      "metadata": {
        "id": "rje0-VIZ4W9C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# from PIL import Image\n",
        "# import tensorflow as tf\n",
        "# from tensorflow.keras.models import load_model\n",
        "# from tensorflow.keras.preprocessing import image\n",
        "# from flask import Flask, render_template, request\n",
        "# from tensorflow.keras.preprocessing.image import load_img\n",
        "# from tensorflow.keras.preprocessing.image import img_to_array\n",
        "\n",
        "# app = Flask(__name__)\n",
        "\n",
        "# def get_model():\n",
        "#     global model\n",
        "#     model = load_model('car_model.hdf5')\n",
        "#     print(\"Model loaded!\")\n",
        "\n",
        "# def load_image(img_path):\n",
        "\n",
        "#     img = image.load_img(img_path)\n",
        "#     img_tensor = image.img_to_array(img)                    # (height, width, channels)\n",
        "#     img_tensor = np.expand_dims(img_tensor, axis=0)         # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n",
        "#     img_tensor /= 255.                                      # imshow expects values in the range [0, 1]\n",
        "\n",
        "#     return img_tensor\n",
        "\n",
        "# def prediction(img_path):\n",
        "#     new_image = load_image(img_path)\n",
        "    \n",
        "#     pred = model.predict(new_image)\n",
        "    \n",
        "#     print(pred)\n",
        "    \n",
        "#     labels=np.array(pred)\n",
        "#     labels[labels>=0.6]=1\n",
        "#     labels[labels<0.6]=0\n",
        "    \n",
        "#     print(labels)\n",
        "#     final=np.array(labels)\n",
        "    \n",
        "#     if final[0][0]==1:\n",
        "#         return \"Damaged Car\"\n",
        "#     else:\n",
        "#         return \"Non Damaged Car\"\n",
        "\n",
        "# get_model()"
      ],
      "metadata": {
        "id": "9_g2Zpkx4yAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model loaded!**"
      ],
      "metadata": {
        "id": "QGuQzPP_47uf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from flask import Flask, request, render_template,jsonify\n",
        "# @app.route(\"/\", methods=['GET', 'POST'], endpoint='func')\n",
        "# def home():\n",
        "\n",
        "#     return render_template('home.html')\n",
        "\n",
        "# @app.route(\"/predict\", methods = ['GET','POST'], endpoint='func2')\n",
        "# def predict():\n",
        "    \n",
        "#     if request.method == 'POST':\n",
        "        \n",
        "#         file = request.files['file']\n",
        "#         filename = file.filename\n",
        "#         file_path = os.path.join(r'/content/drive/MyDrive/car_dent_coco.zip (Unzipped Files)/car_dent_coco/valid/', filename)  #slashes should be handeled properly\n",
        "#         file.save(file_path)\n",
        "#         print(filename)\n",
        "#         product = prediction(file_path)\n",
        "#         print(product)\n",
        "        \n",
        "#     return render_template('predict.html', product = product, user_image = file_path)   #file_path can or may used at the place of filename\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     # app.run()\n",
        "#     app.run(port=5000,debug=True)"
      ],
      "metadata": {
        "id": "8PpTGAZP49ot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***References***\n",
        "\n",
        "# Tutorial-image-classification-with-keras-flow-from-directory-and-generators\n",
        "\n",
        "# *Model deployment using streamlit on Colab* *italicized text*"
      ],
      "metadata": {
        "id": "9Fcx1IT25DB9"
      }
    }
  ]
}